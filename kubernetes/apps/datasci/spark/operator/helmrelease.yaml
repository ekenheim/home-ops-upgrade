apiVersion: helm.toolkit.fluxcd.io/v2
kind: HelmRelease
metadata:
  name: &app spark
  namespace: datasci
spec:
  interval: 30m
  chart:
    spec:
      chart: spark
      version: 10.0.0
      sourceRef:
        kind: HelmRepository
        name: spark-operator
        namespace: flux-system
  install:
    remediation:
      retries: 3
  upgrade:
    cleanupOnFail: true
    remediation:
      strategy: rollback
      retries: 3
  values:
    networkPolicy:
      enabled: true
      master:
        ingress:
          - {}  # Allow all ingress to master
        egress:
          - {}  # Allow all egress from master
      worker:
        ingress:
          - {}  # Allow all ingress to workers
        egress:
          - {}  # Allow all egress from workers
    defaultPodOptions:
      podAnnotations:
        sidecar.istio.io/inject: "true"
        proxy.istio.io/config: '{"holdApplicationUntilProxyStarts": true}'
        traffic.sidecar.istio.io/includeInboundPorts: "7077,8080,6066"
        traffic.sidecar.istio.io/excludeOutboundPorts: "7077"
      securityContext:
        runAsGroup: 65534
        runAsUser: 65534
        runAsNonRoot: true
        seccompProfile:
          type: RuntimeDefault
    service:
      type: ClusterIP
      ports:
        cluster: 7077
        ui: 80
    master:
      service:
        type: ClusterIP
        ports:
          cluster: 7077
          ui: 80
      resources:
        requests:
          cpu: 500m
          memory: 512Mi
        limits:
          cpu: 1000m
          memory: 1Gi
      extraEnv:
        - name: SPARK_MASTER_OPTS
          value: "-Dspark.deploy.recoveryMode=NONE -Dspark.master.rest.enabled=false -Dspark.master.host=spark-master-svc -Dspark.network.timeout=300s -Dspark.rpc.askTimeout=300s -Dspark.rpc.lookupTimeout=300s -Dspark.rpc.netty.dispatcher.numThreads=32 -Dspark.rpc.connect.timeout=300s"
        - name: SPARK_LOCAL_HOSTNAME
          valueFrom:
            fieldRef:
              fieldPath: status.podIP
      extraVolumes:
        - name: spark-checkpoint
          persistentVolumeClaim:
            claimName: spark-checkpoint-pvc
      extraVolumeMounts:
        - name: spark-checkpoint
          mountPath: /mnt/spark-checkpoints
    worker:
      replicas: 4
      resources:
        requests:
          cpu: 500m
          memory: 512Mi
        limits:
          cpu: 1000m
          memory: 50Gi
      extraEnv:
        - name: SPARK_WORKER_OPTS
          value: "-Dspark.worker.cleanup.enabled=false -Dspark.network.timeout=300s -Dspark.rpc.askTimeout=300s -Dspark.rpc.lookupTimeout=300s -Dspark.rpc.netty.dispatcher.numThreads=32 -Dspark.rpc.connect.timeout=300s"
        - name: SPARK_MASTER_URL
          value: "spark://spark-master-svc:7077"
        - name: SPARK_LOCAL_HOSTNAME
          valueFrom:
            fieldRef:
              fieldPath: status.podIP
      extraVolumes:
        - name: spark-checkpoint
          persistentVolumeClaim:
            claimName: spark-checkpoint-pvc
      extraVolumeMounts:
        - name: spark-checkpoint
          mountPath: /mnt/spark-checkpoints
    metrics:
      enabled: true
      serviceMonitor:
        enabled: true
        interval: 10s
    ingress:
      enabled: false
    web:
      enabled: true
      service:
        type: ClusterIP
      ingress:
        enabled: false
