apiVersion: helm.toolkit.fluxcd.io/v2
kind: HelmRelease
metadata:
  name: &app spark
  namespace: datasci
spec:
  interval: 30m
  chart:
    spec:
      chart: spark
      version: 9.4.1
      sourceRef:
        kind: HelmRepository
        name: spark-operator
        namespace: flux-system
  install:
    remediation:
      retries: 3
  upgrade:
    cleanupOnFail: true
    remediation:
      strategy: rollback
      retries: 3
  values:
    defaultPodOptions:
      securityContext:
        runAsGroup: 65534
        runAsUser: 65534
        runAsNonRoot: true
        seccompProfile:
          type: RuntimeDefault
    service:
      type: ClusterIP
      ports:
        cluster: 7077
        ui: 80
    master:
      service:
        type: ClusterIP
        ports:
          cluster: 7077
          ui: 80
      resources:
        requests:
          cpu: 500m
          memory: 512Mi
        limits:
          cpu: 1000m
          memory: 1Gi
      extraEnv:
        - name: SPARK_MASTER_OPTS
          value: "-Dspark.deploy.recoveryMode=ZOOKEEPER -Dspark.deploy.zookeeper.url=spark-zookeeper:2181 -Dspark.deploy.zookeeper.dir=/spark"
      extraVolumes:
        - name: spark-checkpoint
          persistentVolumeClaim:
            claimName: spark-checkpoint-pvc
      extraVolumeMounts:
        - name: spark-checkpoint
          mountPath: /mnt/spark-checkpoints
    worker:
      replicas: 3
      resources:
        requests:
          cpu: 500m
          memory: 512Mi
        limits:
          cpu: 1000m
          memory: 30Gi
      affinity:
        nodeAffinity:
          requiredDuringSchedulingIgnoredDuringExecution:
            nodeSelectorTerms:
              - matchExpressions:
                  - key: kubernetes.io/hostname
                    operator: NotIn
                    values:
                      - "worker3"
      extraEnv:
        - name: SPARK_WORKER_OPTS
          value: "-Dspark.worker.cleanup.enabled=true -Dspark.worker.cleanup.interval=1800 -Dspark.worker.cleanup.appDataTtl=7d"
      extraVolumes:
        - name: spark-checkpoint
          persistentVolumeClaim:
            claimName: spark-checkpoint-pvc
      extraVolumeMounts:
        - name: spark-checkpoint
          mountPath: /mnt/spark-checkpoints
    worker3:
      replicas: 1
      resources:
        requests:
          cpu: 2000m
          memory: 4Gi
        limits:
          cpu: 8000m
          memory: 60Gi
      affinity:
        nodeAffinity:
          requiredDuringSchedulingIgnoredDuringExecution:
            nodeSelectorTerms:
              - matchExpressions:
                  - key: kubernetes.io/hostname
                    operator: In
                    values:
                      - "worker3"
      extraEnv:
        - name: SPARK_WORKER_OPTS
          value: "-Dspark.worker.cleanup.enabled=true -Dspark.worker.cleanup.interval=1800 -Dspark.worker.cleanup.appDataTtl=7d"
      extraVolumes:
        - name: spark-checkpoint
          persistentVolumeClaim:
            claimName: spark-checkpoint-pvc
      extraVolumeMounts:
        - name: spark-checkpoint
          mountPath: /mnt/spark-checkpoints
    metrics:
      enabled: true
      serviceMonitor:
        enabled: true
        interval: 10s
    ingress:
      enabled: false
    web:
      enabled: true
      service:
        type: ClusterIP
      ingress:
        enabled: false
