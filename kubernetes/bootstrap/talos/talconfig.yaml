# yaml-language-server: $schema=https://raw.githubusercontent.com/budimanjojo/talhelper/master/pkg/config/schemas/talconfig.json
---
# renovate: datasource=docker depName=ghcr.io/siderolabs/installer
talosVersion: v1.10.1
# renovate: datasource=docker depName=ghcr.io/siderolabs/kubelet
kubernetesVersion: v1.33.0

clusterName: &cluster home-kubernetes
endpoint: https://192.168.50.10:6443
clusterPodNets:
  - "10.42.0.0/16"
clusterSvcNets:
  - "10.43.0.0/16"
additionalApiServerCertSans: &sans
  - "192.168.50.10"
  - 127.0.0.1 # KubePrism
additionalMachineCertSans: *sans
cniConfig:
  name: none

nodes:
  - hostname: "worker2"
    ipAddress: "192.168.50.32"
    installDisk: "/dev/sdb"
    talosImageURL: factory.talos.dev/installer/5b3717ebb1bc80ddea39bb8ae3cfd3294bfcfb13e05dcd6f1aa54b8e8f9dbcc1
    controlPlane: false
    networkInterfaces:
      - deviceSelector:
          hardwareAddr: 04:0e:3c:21:b2:3f
        dhcp: true
        mtu: 1500
        routes:
          - network: 0.0.0.0/0
            gateway: "192.168.50.1"
  - hostname: "master1"
    ipAddress: "192.168.50.31"
    installDisk: "/dev/sda"
    talosImageURL: factory.talos.dev/installer/5b3717ebb1bc80ddea39bb8ae3cfd3294bfcfb13e05dcd6f1aa54b8e8f9dbcc1
    controlPlane: true
    networkInterfaces:
      - deviceSelector:
          hardwareAddr: 48:21:0b:36:2d:6a
        dhcp: true
        mtu: 1500
        routes:
          - network: 0.0.0.0/0
            gateway: "192.168.50.1"
        vip:
          ip: "192.168.50.10"
  - hostname: "master2"
    ipAddress: "192.168.50.33"
    installDisk: "/dev/sda"
    talosImageURL: factory.talos.dev/installer/5b3717ebb1bc80ddea39bb8ae3cfd3294bfcfb13e05dcd6f1aa54b8e8f9dbcc1
    controlPlane: true
    networkInterfaces:
      - deviceSelector:
          hardwareAddr: 48:21:0b:50:ee:bc
        dhcp: true
        mtu: 1500
        routes:
          - network: 0.0.0.0/0
            gateway: "192.168.50.1"
        vip:
          ip: "192.168.50.10"
  - hostname: "worker1"
    ipAddress: "192.168.50.30"
    installDisk: "/dev/sdb"
    talosImageURL: factory.talos.dev/installer/5b3717ebb1bc80ddea39bb8ae3cfd3294bfcfb13e05dcd6f1aa54b8e8f9dbcc1
    controlPlane: false
    networkInterfaces:
      - deviceSelector:
          hardwareAddr: 94:c6:91:17:18:61
        dhcp: true
        mtu: 1500
        routes:
          - network: 0.0.0.0/0
            gateway: "192.168.50.1"
  - hostname: "master3"
    ipAddress: "192.168.50.34"
    installDisk: "/dev/sda"
    talosImageURL: factory.talos.dev/installer/5b3717ebb1bc80ddea39bb8ae3cfd3294bfcfb13e05dcd6f1aa54b8e8f9dbcc1
    controlPlane: true
    networkInterfaces:
      # 2.5G Internal Port
      - deviceSelector:
          hardwareAddr: 58:47:ca:75:60:0f
        dhcp: true
        mtu: 1500
        routes:
          - network: 0.0.0.0/0
            gateway: "192.168.50.1"
        dhcpOptions:
            routeMetric: 1024
        vip:
          ip: "192.168.50.36"
      # 2.5G Internal Port
      - deviceSelector:
          hardwareAddr: 58:47:ca:75:60:10
        dhcp: true
        mtu: 1500
        routes:
          - network: 0.0.0.0/0
            gateway: "192.168.50.1"
        dhcpOptions:
            routeMetric: 2048
  - hostname: "worker3"
    ipAddress: "192.168.50.155"
    installDisk: "/dev/sda"
    talosImageURL: factory.talos.dev/installer/ecd0d866ae091dff599a16632cad94b1f68be82e5a064ed875cd064474532246
    controlPlane: false
    networkInterfaces:
      - deviceSelector:
          driver: e1000e
          #hardwareAddr: BC:24:11:81:A1:DE
        dhcp: true
        mtu: 1500
        routes:
          - network: 0.0.0.0/0
            gateway: "192.168.50.1"
    schematic:
      customization:
        extraKernelArgs:
          - net.ifnames=0
        systemExtensions:
          officialExtensions:
            - siderolabs/intel-ucode
            - siderolabs/nvidia-container-toolkit-lts
    patches:
      - |-
        - op: add
          path: /machine/kernel
          value:
            modules:
              - name: nvidia
              - name: nvidia_uvm
              - name: nvidia_drm
              - name: nvidia_modeset
      - |-
        - op: add
          path: /machine/sysctls
          value:
            net.core.bpf_jit_harden: 1
      - |-
        - op: add
          path: /machine/files
          value:
            - op: create
              path: /var/etc/nvidia-container-runtime/config.toml
              content: |-
                disable-require = false
                #swarm-resource = "DOCKER_RESOURCE_GPU"
                #accept-nvidia-visible-devices-envvar-when-unprivileged = true
                #accept-nvidia-visible-devices-as-volume-mounts = true

                [nvidia-container-cli]
                #root = "/run/nvidia/driver"
                #path = "/usr/bin/nvidia-container-cli"
                environment = []
                #debug = "/var/log/nvidia-container-toolkit.log"
                #ldcache = "/etc/ld.so.cache"
                load-kmods = true
                #no-cgroups = false
                #user = "root:video"
                ldconfig = "@/sbin/ldconfig.real"

                [nvidia-container-runtime]
                #debug = "/var/log/nvidia-container-runtime.log"

                # Specify the runtimes to use with docker
                [nvidia-container-runtime.runtimes]
                containerd = "/run/containerd/containerd.sock"

patches:
  # Configure containerd
  - |-
    machine:
      files:
        - op: create
          path: /etc/cri/conf.d/20-customization.part
          content: |-
            [plugins."io.containerd.grpc.v1.cri"]
              enable_unprivileged_ports = true
              enable_unprivileged_icmp = true
            [plugins."io.containerd.grpc.v1.cri".containerd]
              discard_unpacked_layers = false
            [plugins."io.containerd.grpc.v1.cri".containerd.runtimes.runc]
              discard_unpacked_layers = false

    # Configure NFS Mounts
  - |-
    machine:
      files:
        - op: overwrite
          path: /etc/nfsmount.conf
          permissions: 420
          content: |-
            [ NFSMount_Global_Options ]
              nfsvers = 4.2
              hard = True
              noatime = True
              nodiratime = True
              rsize = 131072
              wsize = 131072
              nconnect = 8

  # Disable search domain everywhere
  - |-
    machine:
      network:
        disableSearchDomain: true

  # Enable cluster discovery
  - |-
    cluster:
      discovery:
        registries:
          kubernetes:
            disabled: false
          service:
            disabled: false

  # Configure kubelet
  - |-
    machine:
      kubelet:
        extraArgs:
          image-gc-low-threshold: 50
          image-gc-high-threshold: 55
          rotate-server-certificates: true
        nodeIP:
          validSubnets:
            - "192.168.50.0/24"

  # Force nameserver
  - |-
    machine:
      network:
        nameservers:
          - 192.168.1.1
          - 1.1.1.1

  # Configure NTP
  - |-
    machine:
      time:
        disabled: false
        servers:
          - time.cloudflare.com

  # Custom sysctl settings
  - |-
    machine:
      sysctls:
        fs.inotify.max_queued_events: "65536"
        fs.inotify.max_user_watches: "524288"
        fs.inotify.max_user_instances: "8192"
        net.core.rmem_max: "2500000"
        net.core.wmem_max: "2500000"

  # Mount openebs-hostpath in kubelet
  - |-
    machine:
      kubelet:
        extraMounts:
          - destination: /var/openebs/local
            type: bind
            source: /var/openebs/local
            options: ["bind", "rshared", "rw"]

  # Disable predictable NIC naming
  #- |-
  #  machine:
  #    install:
  #      extraKernelArgs:
  #        - net.ifnames=0

controlPlane:
  patches:
    # Cluster configuration
    - |-
      cluster:
        allowSchedulingOnMasters: true
        controllerManager:
          extraArgs:
            bind-address: 0.0.0.0
        coreDNS:
          disabled: true
        proxy:
          disabled: true
        scheduler:
          extraArgs:
            bind-address: 0.0.0.0

    # ETCD configuration
    - |-
      cluster:
        etcd:
          extraArgs:
            listen-metrics-urls: http://0.0.0.0:2381
          advertisedSubnets:
            - "192.168.50.0/24"

    # Disable default API server admission plugins.
    - |-
      - op: remove
        path: /cluster/apiServer/admissionControl

    # Enable K8s Talos API Access
    - |-
      machine:
        features:
          kubernetesTalosAPIAccess:
            enabled: true
            allowedRoles:
              - os:admin
            allowedKubernetesNamespaces:
              - kube-tools

    # Enable hostDNS:
    - |-
      machine:
        features:
          hostDNS:
            enabled: true
            forwardKubeDNSToHost: true
            resolveMemberNames: true
